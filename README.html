<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>readme</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="README_files/libs/clipboard/clipboard.min.js"></script>
<script src="README_files/libs/quarto-html/quarto.js"></script>
<script src="README_files/libs/quarto-html/popper.min.js"></script>
<script src="README_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="README_files/libs/quarto-html/anchor.min.js"></script>
<link href="README_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="README_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="README_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="README_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="README_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="eaps591-weather-simulation-and-prediction-with-cloud-computing" class="level2">
<h2 class="anchored" data-anchor-id="eaps591-weather-simulation-and-prediction-with-cloud-computing">EAPS591: Weather Simulation and Prediction with Cloud Computing</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/2915555/133526401-b79abf6c-ab0d-438d-9927-da39b7c17b96.jpg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">banner</figcaption><p></p>
</figure>
</div>
<section id="welcome" class="level3">
<h3 class="anchored" data-anchor-id="welcome">Welcome</h3>
<p>Welcome to <strong>Cloud Hackathon: Transitioning Earthdata Workflows to the Cloud,</strong> co-hosted by the NASA EOSDIS Physical Oceanography Distributed Active Archive Center (<a href="https://podaac.jpl.nasa.gov/">PO.DAAC</a>), National Snow and Ice Data Center DAAC (<a href="https://nsidc.org/daac">NSIDC DAAC</a>), Land Processes Distributed Active Archive Center (<a href="https://lpdaac.usgs.gov/">LP.DAAC</a>), with support provided by <a href="https://asdc.larc.nasa.gov/">ASDC DAAC</a>, <a href="https://disc.gsfc.nasa.gov">GES DISC</a>, <a href="https://impact.earthdata.nasa.gov/">IMPACT</a>, and <a href="https://nasa-openscapes.github.io/">NASA Openscapes</a> Project.</p>
<p>The Cloud Hackathon will take place <strong>virtually</strong> from <strong>November 15-19, 2021.</strong> The event is free to attend, but an application is required.The application period (September 21 - October 12, 2021) is now closed. Those who applied will be informed of the outcome on or around October 20th, 2021.</p>
</section>
<section id="about" class="level3">
<h3 class="anchored" data-anchor-id="about">About</h3>
<p>The <strong>Cloud Hackathon: Transitioning Earthdata Workflows to the Cloud</strong> is a virtual 5-day (4 hours per day) collaborative open science learning experience aimed at exploring, creating, and promoting effective cloud-based science and applications workflows using NASA Earthdata Cloud data, tools, and services (among others), in support of Earth science data processing and analysis in the era of big data. Its goals are to:</p>
<ol type="1">
<li><strong>Introduce</strong> Earth science data users to NASA Earthdata cloud-based data products, tools and services in order to increase awareness and support transition to cloud-based science and applications workflows.</li>
<li><strong>Enable</strong> science and applications workflows in the cloud that leverage NASA Earth Observations and capabilities (services) from within the NASA Earthdata Cloud, hosted in Amazon Web Services (AWS) cloud, thus increasing NASA Earthdata data utility and meaningfulness for science and applications use cases.</li>
<li><strong>Foster community engagement</strong> utilizing Earthdata cloud tools and services in support of open science and open data.</li>
</ol>
<p><strong>Outcome</strong>: Participants prototype their science and applications workflows (via hackathon projects) that leverage Earthdata Cloud data and services (focusing on, but not limited to, oceanography, cryosphere, hydrology and land data), which supports them in their transition to cloud-based or hybrid workflows for data processing and analysis.</p>
<p>This is an opportunity for researchers that might not yet have had the opportunity to work in the Cloud to explore, learn and prototype workflows with NASA Earthdata in the Cloud, but more intermediate or advanced cloud users interested in further exploring cloud workflows with Earthdata Cloud data and service are also welcome.</p>
</section>
<section id="application" class="level3">
<h3 class="anchored" data-anchor-id="application">Application</h3>
<section id="information-for-applicants" class="level4">
<h4 class="anchored" data-anchor-id="information-for-applicants">Information for applicants</h4>
<p>The Cloud Hackathon will be a virtual event held November 15-19, 2021, where participants will explore the intersection of Earth science data, cloud computing, and big data analysis through demonstration tutorials and hands-on “hacking” projects. To best benefit from the event, we recommend some familiarity or experience with:</p>
<ul>
<li>NASA Earthdata data (focusing on oceanography, cryosphere, hydrology, cryosphere and land data, including interdisciplinary applications); and</li>
<li>Programming skills using Python. We plan to accept participants with diverse skill levels and backgrounds in programming. However, to best benefit from and contribute to the program, participants are expected to have some experience with Python programming.</li>
</ul>
<p>No cloud computing experience is required, but we encourage both beginner and more experienced participants with AWS cloud to apply.</p>
<p>If selected, participants will have the option to attend a Carpentries-style github, python, shell scripting clinic ahead of the Cloud Hachathon.</p>
</section>
<section id="application-form" class="level4">
<h4 class="anchored" data-anchor-id="application-form">Application Form</h4>
<p>In the application form, we encourage you to think about and provide a science use case that you would like to prototype in the cloud. At the beginning of the hackathon, participants will be able to pitch their use case to support the formation of “hack” projects - by which we mean collaboratively experiment working in with NASA Earthdata data and capabilities in the Cloud. During the hackathon, participants will get into teams of their choosing, around a common use case to “hack” in the cloud. The use cases provided in the application form will also help the organizers best prepare materials tailored to those use cases.</p>
<p><strong>The application period has now closed. Thank you for your interest.</strong></p>
</section>
</section>
<section id="what-to-expect" class="level3">
<h3 class="anchored" data-anchor-id="what-to-expect">What to expect</h3>
<ul>
<li>During the Cloud Hackathon, the selected participants will have access to cloud environments in AWS through a JupyterHub interface, provided through 2i2c.</li>
<li>Participants will be guided on how to log into the cloud environment, import needed data recipes and resources, and will have the opportunity to explore and develop science and applications workflows in a cloud environment (hosted in AWS) using example tutorials as building blocks.</li>
<li>The Cloud Hackathon is an open science event: all tutorials and examples are developed openly and will be publicly available during and following hackathon. Participants will strengthen their practice of open science, using open source code and “hacking” their projects openly to enable further discovery and contributions by the broader open community following the hackathon.</li>
<li>Throughout the hackathon, participants will learn about NASA’s Earthdata move to the cloud and Earthdata APIs for data discovery, access, and transformations to enable faster, more efficient time to science.</li>
</ul>
<p>In the two to three weeks leading up to the hackathon, participants are encouraged to review <strong>background resources</strong> that will facilitate a more effective hackathon experience. These resources will be shared here leading up to the Hackathon dates, and will be accessible to all data users, whether they attend the hackathon or not.</p>
<p><strong>The following datasets are currently available from the NASA Earthdata Cloud.</strong> Participants can choose to prototype a cloud-based science workflow using a combination of these datasets, as well as other non-Earthdata Cloud data. If your preferred dataset is not yet available in the Earthdata Cloud, consider using a current cloud-based dataset as proxy to explore prototyping.</p>
<ul>
<li><a href="https://search.earthdata.nasa.gov/search?ff=Available%20from%20AWS%20Cloud">https://search.earthdata.nasa.gov/search?ff=Available%20from%20AWS%20Cloud</a></li>
</ul>
<p><strong>Example</strong> <strong>use</strong> <strong>cases</strong> to explore in the cloud (note these are for inspiration only, you are not limited to these workflows):</p>
<ul>
<li>Use the advanced wildcard search capabilities in Earthdata Search Client/Common Metadata Repository (CMR) to precisely search/select all cloud-archived Sentinel-6A granules
<ul>
<li>from a specific cycle (i.e.&nbsp;a sequence orbits that together provide global spatial coverage), and/or</li>
<li>from a specific pass(es) over multiple cycles (i.e.&nbsp;selected orbits over a series of cycles that together provide a time series coverage).</li>
<li>Then, prepare the data for gridding or for local analysis at space/time scales which are appropriate for the target analysis (and limited by default given the length of S6A data record…)</li>
</ul></li>
<li>Time series analysis across multi-mission measurements spanning data housed both within and outside of NASA Earthdata Cloud, to develop a workflow that can accommodate different data locations, as data continue to migrate to the Cloud:
<ul>
<li>Programmatically search for a data variable (e.g.&nbsp;altimetry measurements) at a single point or area of interest across multiple datasets and identify whether the data are available in the Cloud</li>
<li>Acquire the data based on archived location and combine in order to produce a homogenous time series</li>
</ul></li>
<li>Explore/leverage cloud-optimized formats (COFs) such as Zarr to compute global or regional climatology and anomalies for a large-volume dataset (e.g.&nbsp;1-km MUR SST) without having to download data (in-cloud analysis).</li>
<li>Subset Level 2 swath dataset of interest spatially and for specific variable and do some exploratory analysis and visualization from within the cloud.</li>
<li>Use NASA’s CMR-STAC API to search and discover Harmonized Landsat Sentinel-2 (HLS) cloud assets based on cloud data products, area of interest, and date range query parameters.</li>
<li>Harmonized Landsat Sentinel-2 (HLS) for land monitoring: access, explore, and visualize time series surface reflectance data in the cloud.</li>
</ul>
<p>This event is motivated by the dawn of the era of Big Data. NASA’s Earth Observing System Data and Information System (EOSDIS) is in the process of moving EOSDIS data to the cloud, driven by a rapid rate of data ingest into the EOSDIS archive. NASA remote sensing data from both upcoming (e.g.&nbsp;SWOT) and existing (e.g.&nbsp;Terra, Aqua, ICESat-2) missions will be available in the Earthdata Cloud platform in the coming years. The paradigm shift from on-premise (local) to cloud-based data distribution, and that from “download and analyze” to “analysis in place” present opportunities and challenges. Guiding users through this transition is of the utmost importance.</p>
<p>Cloud Hackathon: Transitioning Earthdata Workflows to the Cloud is co-hosted by NASA’s PO.DAAC, NSIDC DAAC, LP.DAAC, with support from ASDC DAAC, GES DISC and the NASA Openscapes Project, and cloud computing infrastructure by 2i2c. <br> <img src="https://user-images.githubusercontent.com/2915555/133525653-2a2278b1-1015-4350-b2a5-160d125aaaf7.png" class="img-fluid" alt="Screen Shot 2021-09-15 at 5 22 15 PM"> <br></p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>