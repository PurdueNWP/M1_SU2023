{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "author: Wen-wen Tung and YOUR NAME\n",
        "editor:\n",
        "  markdown:\n",
        "    wrap: 72\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    number-sections: false\n",
        "    code-fold: true\n",
        "    embed-resources: true\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assignment 1: Getting Started with Anvil and Github\n",
        "\n",
        "## 1. Introduction:\n",
        "\n",
        "In this assignment, you will use this Quarto document to execute python commands that load and visualize the surface temperature data of the Jan 2016 Blizzard. Then, you will create a polished webpage and a Word report for submission.  \n",
        "\n",
        "The first block of the document source code is called the YAML, a human-readable data-serialization language. It is commonly used to add **metadata**, such as title and descriptions, to Markdown documents. For Quarto specifically, it can include the method to render the document, such as the Jupyter engine specified with **Jupyter: python**.\n",
        "\n",
        "\n",
        "Moreover, you will learn to perform the following tasks:\n",
        "\n",
        " - Subsetting and download data directly from NOAA Physical Sciences Laboratory.\n",
        " - Plot the surface temperature field using filled contours over a map\n",
        "\n",
        "The weather event under investigation is the January 2016 Blizzard, although the tasks are generic and it would be easy to change to other events. \n",
        "\n",
        "#### References:\n",
        "\n",
        "- Description of the Jan 2016 Blizzard in the Course Brightspace Site, Week 1 Learning Materials\n",
        "- Unidata MetPy tutorial: https://unidata.github.io/python-training/workshop/MetPy_Case_Study/metpy-case-study/\n",
        "\n",
        "\n",
        "## 2. Load Python packages\n",
        "\n",
        "All of these packages are already installed for you. When evoking the `launchstudio` command, the necessary Python module and environment are loaded. In short, you should not need to install any of these packages. If you encounter error messages related to missing packages, please contact the instructors as soon as possible. \n",
        "\n",
        "Click on the little advancing arrow on the top right of each code chunk to run the entire chunk. Click on the down-pointing arrow to run all chunks before the current one. To preview the document, click on the *Render* button. A HTML (web) file will be created for you to view."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from datetime import datetime\n",
        "\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from metpy.units import units\n",
        "from netCDF4 import Dataset, num2date\n",
        "from scipy.ndimage import gaussian_filter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Case Study Data\n",
        "\n",
        "*North American Regional Reanalysis (NARR)* is a high resolution combined model and assimilated dataset produced by the National Centers for Environmental Prediction (NCEP). From 1979 to near present 8-times daily, daily and monthly data is output on a Northern Hemisphere Lambert Conformal Conic grid. It is a regional reanalysis of North America containing temperatures, winds, moisture,\n",
        "soil data, and dozens of other parameters at 32km horizontal resolution.\n",
        "\n",
        "Let's investigate what specific NARR output is available to work with\n",
        "from NOAA Physical Sciences Laboratory: [https://psl.noaa.gov/data/gridded/data.narr.html](https://psl.noaa.gov/data/gridded/data.narr.html)\n",
        "\n",
        "We specifically want to download the data using the *THREDDS Catalog* option, such as in [https://psl.noaa.gov/thredds/catalog/Datasets/NARR/monolevel/catalog.html](https://psl.noaa.gov/thredds/catalog/Datasets/NARR/monolevel/catalog.html). The 2016 surface temperature data are available for manual subsetting through the THREDDS data server NetCDF Subset Service [https://psl.noaa.gov/thredds/ncss/grid/Datasets/NARR/monolevel/air.sfc.2016.nc/dataset.html](https://psl.noaa.gov/thredds/ncss/grid/Datasets/NARR/monolevel/air.sfc.2016.nc/dataset.html).\n",
        "\n",
        "We subset the **3-hourly air temperature at Surface** data in **Latitude** and **Longitude** to the North American domain bounded by **North=60, South=18, East=300, and West=225** degrees at a single time **2016-01-23T12:00:00Z**. The data is output into the Network Common Data Form ([NetCDF](https://www.unidata.ucar.edu/software/netcdf/)) format, a\n",
        "standard for sharing scientific data in the weather and climate\n",
        "community. Specifically, choose the **netcdf4-classic* format. Leave the Vertical Subset and CF Compliance options blank. The resulted NCSS Request URL is:\n",
        "\n",
        "https://psl.noaa.gov/thredds/ncss/grid/Datasets/NARR/monolevel/air.sfc.2016.nc?var=air&var=lat&var=lon&north=60&west=225&east=300&south=18&horizStride=1&time=2016-01-23T12:00:00Z&&accept=netcdf4-classic\n",
        "\n",
        "Submit this request, then a dataset named `air.sfc.2016.nc.nc4` will be downloaded to your personal computer. For your convenience, the same data is stored in Anvil for you to use. We use the `Dataset` function in the python `netCDF4` package to read this file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = Dataset('/anvil/projects/nwp/depot/DATA/Week1/air.sfc.2016.nc.nc4', 'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see what dimensions are in the file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.dimensions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The variable name of the surface Temperature is `air`. We could display some information about `air` stored in the file. Here, we see that the unit of the `air` values is degree K, hence their valid range is between 180K and 365K."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(data['air'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Plotting data\n",
        "\n",
        "Due to the curvilinear nature of the NARR grid, there is a need to smooth the data that we imported for calculation and plotting purposes. Additionally, we want to attach units to our values for use in MetPy calculations later and it will also allow for easy conversion to other units. \n",
        "\n",
        "### Data Preparation\n",
        "\n",
        "In the following code, we use the gaussian_filter function to smooth the `air` from the netCDF file with a sigma value of 1. Then, we assign the units of kelvin to the temperature. Lastly, we extract the `lat` and `lon` variables from the file. `lev` is set to zero for surface values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extract data and assign units\n",
        "tmpk = gaussian_filter(data.variables['air'][0],\n",
        "                       sigma=1.0) * units.K\n",
        "# Extract coordinate data for plotting\n",
        "lat = data.variables['lat'][:]\n",
        "lon = data.variables['lon'][:]\n",
        "lev = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we need to extract the time variable. It's not in very useful\n",
        "units, but the `num2date` function can be used to easily create regular\n",
        "datetime objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "time = data.variables['time']\n",
        "print(time.units)\n",
        "vtime = num2date(time[0], units=time.units)\n",
        "print(vtime)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Maps and Projections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data projection; NARR Data is Earth Relative\n",
        "dataproj = ccrs.PlateCarree()\n",
        "\n",
        "# Plot projection\n",
        "# The look you want for the view, Lambert Conformal for mid-latitude view\n",
        "plotproj = ccrs.LambertConformal(central_longitude=-100., central_latitude=40.,\n",
        "                                 standard_parallels=[30, 60])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def create_map_background():\n",
        "    fig=plt.figure(figsize=(14, 12))\n",
        "    ax=plt.subplot(111, projection=plotproj)\n",
        "    ax.set_extent([-125, -73, 25, 50],ccrs.PlateCarree())\n",
        "    ax.coastlines('50m', linewidth=0.75)\n",
        "    ax.add_feature(cfeature.STATES, linewidth=0.5)\n",
        "    return fig, ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = create_map_background()\n",
        "\n",
        "# Contour 1 - Temperature, dotted\n",
        "cs2 = ax.contour(lon, lat, tmpk.to('degC'), range(-50, 50, 5),\n",
        "                 colors='grey', linestyles='dotted', transform=dataproj)\n",
        "\n",
        "plt.clabel(cs2, fontsize=10, inline=1, inline_spacing=10, fmt='%i',\n",
        "           rightside_up=True, use_clabeltext=True)\n",
        "\n",
        "# Filled contours - Temperature\n",
        "contours = range(-25, 25, 5) \n",
        "# Try change contours such as [-20, -15, -10, -5, -3 -1 0, 5, 10, 15, 20]\n",
        "cf = ax.contourf(lon, lat, tmpk.to('degC'), contours,\n",
        "                 cmap='bwr', extend='both', transform=dataproj)\n",
        "plt.colorbar(cf, orientation='horizontal', pad=0, aspect=50,\n",
        "             extendrect=True, ticks=contours)\n",
        "\n",
        "# Titles\n",
        "plt.title('Surface Temperature degC', loc='left')\n",
        "plt.title(f'VALID: {vtime}', loc='right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Question\n",
        "\n",
        "\n",
        "[![Jan 2016 Blizzard](https://upload.wikimedia.org/wikipedia/commons/2/26/Noaa-forecast-20160122.gif)](National Weather Service 24. hour forecast for blizzard in the eastern United States, for January 22-23, 2016)\n",
        "\n",
        "Compare the surface temperature observation at 12UTC, Jan 23, 2016 against the prediction of precipitation (green=rain, blue=snow, orange=ice, purple=mixed type) from National Weather Service above.\n",
        "Do you think the prediction performed reasonably well in distinguishing the rain and snow apart and why? Please type your answer directly below.\n",
        "\n",
        "(Type Your Answer Here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 6. Create a Word document \n",
        "\n",
        "Save your changes to the file. Type in the *Terminal*:\n",
        "\n",
        "```\n",
        "cd ~/NWP1/Week1\n",
        "quarto render Assignment1_Getting_Started.qmd --to docx\n",
        "```\n",
        "A Word file, `Assignment1_Getting_Started.docx` will be created for you to submit to the Brightspace portal.\n",
        "\n",
        "If you are using Jupyter Notebook `Assignment1_Getting_Started.ipynb`, then render it with the following command in the *Terminal*.\n",
        "\n",
        "```\n",
        "quarto render Assignment1_Getting_Started.ipynb --execute --to docx\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}